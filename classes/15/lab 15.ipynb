{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "data = pd.read_csv(\"../14/data/stumbleupon.tsv.gz\", sep='\\t',\n",
    "                  encoding=\"utf-8\")\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=False,\n",
    "                     stop_words='english',\n",
    "                     min_df=3)\n",
    "\n",
    "docs = cv.fit_transform(data.body.dropna())\n",
    "\n",
    "id2word = dict(enumerate(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "\n",
    "corpus = Sparse2Corpus(docs, documents_columns=False)\n",
    "\n",
    "lda_model = LdaModel(corpus=corpus, id2word = id2word, num_topics=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "(u'0.015*\"images\" + 0.014*\"image\" + 0.011*\"2011\" + 0.011*\"link\" + 0.010*\"small\" + 0.010*\"track\" + 0.009*\"buzz\" + 0.009*\"campaign\" + 0.009*\"sports\" + 0.008*\"jpg\"',)\n",
      "Topic: 1\n",
      "(u'0.007*\"people\" + 0.007*\"said\" + 0.006*\"news\" + 0.004*\"time\" + 0.004*\"health\" + 0.003*\"year\" + 0.003*\"like\" + 0.003*\"world\" + 0.003*\"years\" + 0.003*\"just\"',)\n",
      "Topic: 2\n",
      "(u'0.006*\"new\" + 0.006*\"sports\" + 0.005*\"just\" + 0.005*\"like\" + 0.004*\"world\" + 0.004*\"time\" + 0.004*\"swimsuit\" + 0.004*\"year\" + 0.004*\"si\" + 0.003*\"said\"',)\n",
      "Topic: 3\n",
      "(u'0.009*\"video\" + 0.005*\"twitter\" + 0.004*\"append\" + 0.004*\"text\" + 0.004*\"apple\" + 0.004*\"like\" + 0.004*\"news\" + 0.004*\"new\" + 0.004*\"function\" + 0.004*\"left\"',)\n",
      "Topic: 4\n",
      "(u'0.006*\"use\" + 0.006*\"skin\" + 0.004*\"data\" + 0.004*\"health\" + 0.004*\"like\" + 0.004*\"food\" + 0.004*\"information\" + 0.004*\"water\" + 0.003*\"products\" + 0.003*\"using\"',)\n",
      "Topic: 5\n",
      "(u'0.009*\"fashion\" + 0.007*\"10\" + 0.005*\"11\" + 0.005*\"pm\" + 0.005*\"dress\" + 0.004*\"12\" + 0.004*\"just\" + 0.004*\"look\" + 0.004*\"funny\" + 0.004*\"08\"',)\n",
      "Topic: 6\n",
      "(u'0.009*\"new\" + 0.009*\"technology\" + 0.006*\"future\" + 0.005*\"google\" + 0.004*\"like\" + 0.004*\"best\" + 0.004*\"computer\" + 0.004*\"use\" + 0.004*\"just\" + 0.003*\"design\"',)\n",
      "Topic: 7\n",
      "(u'0.018*\"com\" + 0.015*\"online\" + 0.012*\"www\" + 0.012*\"http\" + 0.010*\"guide\" + 0.008*\"damascus\" + 0.005*\"like\" + 0.004*\"just\" + 0.004*\"don\" + 0.004*\"day\"',)\n",
      "Topic: 8\n",
      "(u'0.009*\"chicken\" + 0.009*\"cup\" + 0.008*\"add\" + 0.006*\"food\" + 0.006*\"oil\" + 0.006*\"recipe\" + 0.006*\"recipes\" + 0.006*\"sauce\" + 0.006*\"cook\" + 0.006*\"salad\"',)\n",
      "Topic: 9\n",
      "(u'0.010*\"add\" + 0.009*\"cup\" + 0.008*\"minutes\" + 0.008*\"cheese\" + 0.007*\"pasta\" + 0.007*\"cookies\" + 0.007*\"recipe\" + 0.007*\"chocolate\" + 0.007*\"eggs\" + 0.006*\"recipes\"',)\n",
      "Topic: 10\n",
      "(u'0.010*\"food\" + 0.009*\"2009\" + 0.008*\"2010\" + 0.007*\"2008\" + 0.007*\"2007\" + 0.007*\"foods\" + 0.006*\"2006\" + 0.005*\"april\" + 0.005*\"august\" + 0.005*\"september\"',)\n",
      "Topic: 11\n",
      "(u'0.013*\"flashvars\" + 0.011*\"com\" + 0.010*\"http\" + 0.007*\"www\" + 0.006*\"href\" + 0.005*\"like\" + 0.004*\"content\" + 0.004*\"just\" + 0.004*\"best\" + 0.004*\"game\"',)\n",
      "Topic: 12\n",
      "(u'0.010*\"cup\" + 0.009*\"chocolate\" + 0.009*\"recipe\" + 0.009*\"butter\" + 0.008*\"sugar\" + 0.007*\"make\" + 0.007*\"minutes\" + 0.006*\"baking\" + 0.006*\"just\" + 0.006*\"add\"',)\n",
      "Topic: 13\n",
      "(u'0.008*\"body\" + 0.007*\"sleep\" + 0.007*\"health\" + 0.005*\"brain\" + 0.005*\"time\" + 0.004*\"make\" + 0.004*\"help\" + 0.004*\"like\" + 0.004*\"just\" + 0.004*\"people\"',)\n",
      "Topic: 14\n",
      "(u'0.030*\"raw\" + 0.011*\"foods\" + 0.010*\"food\" + 0.009*\"healthy\" + 0.008*\"diet\" + 0.008*\"health\" + 0.005*\"eat\" + 0.005*\"day\" + 0.005*\"exercise\" + 0.004*\"protein\"',)\n"
     ]
    }
   ],
   "source": [
    "num_topics = 15\n",
    "num_words_per_topic = 10\n",
    "for ti, topic in enumerate(lda_model.show_topics(num_topics = num_topics, \n",
    "                                                 num_words = num_words_per_topic)):\n",
    "    print(\"Topic: {}\".format(ti))\n",
    "    print topic[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "text = data.body.dropna().map(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'cupcake', 0.9114097356796265),\n",
       " (u'crust', 0.8440617918968201),\n",
       " (u'pie', 0.8420896530151367),\n",
       " (u'cake', 0.8395797610282898),\n",
       " (u'cheesecake', 0.8327450752258301),\n",
       " (u'tart', 0.8247241973876953),\n",
       " (u'brownies', 0.8213274478912354),\n",
       " (u'mini', 0.815024733543396),\n",
       " (u'candy', 0.8143845200538635),\n",
       " (u'pancake', 0.8102335929870605)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['cookie', 'brownie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
